{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNdTLlqf32OOP8h9/6kPlob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gasmibouthaina/-Diabetes-Prediction/blob/main/MLModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build and test your first machine learning model using python and scikit-learn\n",
        "##Table of Contents\n",
        "Load libraries**\n",
        "\n",
        "Data exploration\n",
        "\n",
        "Prepare data for building classification model\n",
        "\n",
        "Split data into train and test sets\n",
        "\n",
        "Helper methods for graph generation\n",
        "\n",
        "Prepare Random Forest classification model\n",
        "\n",
        "Train Random Forest classification model\n",
        "\n",
        "Test Random Forest classification model\n",
        "\n",
        "Evaluate Random Forest classification model"
      ],
      "metadata": {
        "id": "0qofYT0prr6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load libraries"
      ],
      "metadata": {
        "id": "XpmGP1gOsMn4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBmmBPM_reF2"
      },
      "outputs": [],
      "source": [
        "!pip install pandas==0.24.2\n",
        "!pip install --user pandas_ml==0.6.1\n",
        "#downgrade matplotlib to bypass issue with confusion matrix being chopped out\n",
        "!pip install matplotlib==3.1.0\n",
        "!pip install --user scikit-learn==0.21.3\n",
        "!pip install -q scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as mpatches\n",
        "import scikitplot as skplt"
      ],
      "metadata": {
        "id": "YGwSq0jAsXYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data exploration"
      ],
      "metadata": {
        "id": "eTGeAEncsbmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn_pd = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/IBM/ml-learning-path-assets/master/data/mergedcustomers_missing_values_GENDER.csv\")\n",
        "df_churn_pd.head()"
      ],
      "metadata": {
        "id": "Tn3HZkcUsdix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The dataset contains columns of the following data types : \\n\" +str(df_churn_pd.dtypes))\n"
      ],
      "metadata": {
        "id": "Xp1UITEnsmKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The dataset contains following number of records for each of the columns : \\n\" +str(df_churn_pd.count()))\n"
      ],
      "metadata": {
        "id": "p2K8gZYnsr24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data preparation"
      ],
      "metadata": {
        "id": "izCIam5gt0LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove columns that are not required\n",
        "df_churn_pd = df_churn_pd.drop(['ID'], axis=1)\n",
        "\n",
        "df_churn_pd.head()"
      ],
      "metadata": {
        "id": "ZNl9nw2Dt5x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the categorical columns \n",
        "categoricalColumns = ['GENDER', 'STATUS', 'HOMEOWNER']\n",
        "\n",
        "print(\"Categorical columns : \" )\n",
        "print(categoricalColumns)\n",
        "\n",
        "impute_categorical = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "onehot_categorical =  OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[('impute',impute_categorical),('onehot',onehot_categorical)])"
      ],
      "metadata": {
        "id": "Xw_YmVSat--b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data frame for splitting data into train and test datasets\n",
        "\n",
        "features = []\n",
        "features = df_churn_pd.drop(['CHURNRISK'], axis=1)\n",
        "\n",
        "label_churn = pd.DataFrame(df_churn_pd, columns = ['CHURNRISK']) \n",
        "label_encoder = LabelEncoder()\n",
        "label = df_churn_pd['CHURNRISK']\n",
        "\n",
        "label = label_encoder.fit_transform(label)\n",
        "print(\"Encoded value of Churnrisk after applying label encoder : \" + str(label))"
      ],
      "metadata": {
        "id": "y-AsiXxFuxKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "area = 75\n",
        "x = df_churn_pd['ESTINCOME']\n",
        "y = df_churn_pd['DAYSSINCELASTTRADE']\n",
        "z = df_churn_pd['TOTALDOLLARVALUETRADED']\n",
        "\n",
        "pop_a = mpatches.Patch(color='#BB6B5A', label='High')\n",
        "pop_b = mpatches.Patch(color='#E5E88B', label='Medium')\n",
        "pop_c = mpatches.Patch(color='#8CCB9B', label='Low')\n",
        "def colormap(risk_list):\n",
        "    cols=[]\n",
        "    for l in risk_list:\n",
        "        if l==0:\n",
        "            cols.append('#BB6B5A')\n",
        "        elif l==2:\n",
        "            cols.append('#E5E88B')\n",
        "        elif l==1:\n",
        "            cols.append('#8CCB9B')\n",
        "    return cols\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "fig.suptitle('2D and 3D view of churnrisk data')\n",
        "\n",
        "# First subplot\n",
        "ax = fig.add_subplot(1, 2,1)\n",
        "\n",
        "ax.scatter(x, y, alpha=0.8, c=colormap(label), s= area)\n",
        "ax.set_ylabel('DAYS SINCE LAST TRADE')\n",
        "ax.set_xlabel('ESTIMATED INCOME')\n",
        "\n",
        "plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "\n",
        "# Second subplot\n",
        "ax = fig.add_subplot(1,2,2, projection='3d')\n",
        "\n",
        "ax.scatter(z, x, y, c=colormap(label), marker='o')\n",
        "\n",
        "ax.set_xlabel('TOTAL DOLLAR VALUE TRADED')\n",
        "ax.set_ylabel('ESTIMATED INCOME')\n",
        "ax.set_zlabel('DAYS SINCE LAST TRADE')\n",
        "\n",
        "plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q8xtkvlZu0FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Split data into test and train\n",
        "\n"
      ],
      "metadata": {
        "id": "aujHJXFVu_wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features,label , random_state=0)\n",
        "print(\"Dimensions of datasets that will be used for training : Input features\"+str(X_train.shape)+ \n",
        "      \" Output label\" + str(y_train.shape))\n",
        "print(\"Dimensions of datasets that will be used for testing : Input features\"+str(X_test.shape)+ \n",
        "      \" Output label\" + str(y_test.shape))"
      ],
      "metadata": {
        "id": "CplUZTgqu6jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Helper methods for graph generation\n"
      ],
      "metadata": {
        "id": "CPpev4g1vNHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colormap(risk_list):\n",
        "    cols=[]\n",
        "    for l in risk_list:\n",
        "        if l==0:\n",
        "            cols.append('#BB6B5A')\n",
        "        elif l==2:\n",
        "            cols.append('#E5E88B')\n",
        "        elif l==1:\n",
        "            cols.append('#8CCB9B')\n",
        "    return cols\n",
        "\n",
        "def two_d_compare(y_test,y_pred,model_name):\n",
        "    #y_pred = label_encoder.fit_transform(y_pred)\n",
        "    #y_test = label_encoder.fit_transform(y_test)\n",
        "    area = (12 * np.random.rand(40))**2 \n",
        "    plt.subplots(ncols=2, figsize=(10,4))\n",
        "    plt.suptitle('Actual vs Predicted data : ' +model_name + '. Accuracy : %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(X_test['ESTINCOME'], X_test['DAYSSINCELASTTRADE'], alpha=0.8, c=colormap(y_test))\n",
        "    plt.title('Actual')\n",
        "    plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(X_test['ESTINCOME'], X_test['DAYSSINCELASTTRADE'],alpha=0.8, c=colormap(y_pred))\n",
        "    plt.title('Predicted')\n",
        "    plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "x = X_test['TOTALDOLLARVALUETRADED']\n",
        "y = X_test['ESTINCOME']\n",
        "z = X_test['DAYSSINCELASTTRADE']\n",
        "\n",
        "pop_a = mpatches.Patch(color='#BB6B5A', label='High')\n",
        "pop_b = mpatches.Patch(color='#E5E88B', label='Medium')\n",
        "pop_c = mpatches.Patch(color='#8CCB9B', label='Low')\n",
        "\n",
        "def three_d_compare(y_test,y_pred,model_name):\n",
        "    fig = plt.figure(figsize=(12,10))\n",
        "    fig.suptitle('Actual vs Predicted (3D) data : ' +model_name + '. Accuracy : %.2f' % accuracy_score(y_test, y_pred))\n",
        "    \n",
        "    ax = fig.add_subplot(121, projection='3d')\n",
        "    ax.scatter(x, y, z, c=colormap(y_test), marker='o')\n",
        "    ax.set_xlabel('TOTAL DOLLAR VALUE TRADED')\n",
        "    ax.set_ylabel('ESTIMATED INCOME')\n",
        "    ax.set_zlabel('DAYS SINCE LAST TRADE')\n",
        "    plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "    plt.title('Actual')\n",
        "\n",
        "    ax = fig.add_subplot(122, projection='3d')\n",
        "    ax.scatter(x, y, z, c=colormap(y_pred), marker='o')\n",
        "    ax.set_xlabel('TOTAL DOLLAR VALUE TRADED')\n",
        "    ax.set_ylabel('ESTIMATED INCOME')\n",
        "    ax.set_zlabel('DAYS SINCE LAST TRADE')\n",
        "    plt.legend(handles=[pop_a,pop_b,pop_c])\n",
        "    plt.title('Predicted')\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def model_metrics(y_test,y_pred):\n",
        "    print(\"Decoded values of Churnrisk after applying inverse of label encoder : \" + str(np.unique(y_pred)))\n",
        "\n",
        "    skplt.metrics.plot_confusion_matrix(y_test,y_pred,text_fontsize=\"small\",cmap='Greens',figsize=(6,4))\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"The classification report for the model : \\n\\n\"+ classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "btffsyvvvLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Prepare Random Forest classification model\n"
      ],
      "metadata": {
        "id": "-pac-dVOvf8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_name = \"Random Forest Classifier\"\n",
        "\n",
        "randomForestClassifier = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
      ],
      "metadata": {
        "id": "Wpd6WnpwvfP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_model = Pipeline(steps=[('preprocessorAll',preprocessorForAllColumns),('classifier', randomForestClassifier)])\n"
      ],
      "metadata": {
        "id": "DPZO1KjGwVah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}