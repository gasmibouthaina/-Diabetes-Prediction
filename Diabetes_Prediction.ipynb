{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes-Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUvnSVQk4td9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes = pd.read_csv(\"/content/diabetes-dataset.csv\" , delimiter=\",\")\n",
        "df_diabetes[0:8]"
      ],
      "metadata": {
        "id": "7LGeYSJk6xMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes.shape"
      ],
      "metadata": {
        "id": "LtNsdygN67bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes.isnull().any().any()"
      ],
      "metadata": {
        "id": "B1_QqTXE7InH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diabetes.describe()"
      ],
      "metadata": {
        "id": "V6Uyva0c7Ylw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(16,10))  \n",
        "sns.set(font_scale=2.0)\n",
        "sns.heatmap(df_diabetes.corr() , annot= True, linewidths=3, ax=ax)"
      ],
      "metadata": {
        "id": "ML0CKT2E7zpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cdf= df_diabetes[['Glucose', 'BMI', 'Age', 'Outcome']]\n",
        "sns.set(font_scale=0.2)\n",
        "sns.pairplot(cdf)"
      ],
      "metadata": {
        "id": "oP6qqHZ67_08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn.categorical import boxplot\n",
        "plt.figure(figsize=(10,8))\n",
        "boxplot= df_diabetes.boxplot(column=['Glucose', 'BMI', 'Age' , 'BloodPressure'])"
      ],
      "metadata": {
        "id": "n3d03Qil8w2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df_diabetes[['Glucose', 'BMI', 'Age']]\n",
        "y = df_diabetes['Outcome']"
      ],
      "metadata": {
        "id": "xgn4yCII9rQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "#By default, cross_val_score performs three-fold cross-validation, returning three accuracy values. I change the number of folds\n",
        "#used by changing the cv parameter.\n",
        "scores = cross_val_score(logreg, x, y, cv=10)\n",
        "print(\"cross-validation scores: \", scores)\n",
        "print('Mean of cross-validation accuracy: {:.2f}' .format(scores.mean()))"
      ],
      "metadata": {
        "id": "vfMlq5SJ-KGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Qp6cdbxc_KL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "best_score = 0\n",
        "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "        # for each combination of parameters\n",
        "        # train an SVC\n",
        "        svm = SVC(gamma=gamma, C=C)\n",
        "        # perform cross-validation\n",
        "        scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
        "        # compute mean cross-validation accuracy\n",
        "        score = np.mean(scores)\n",
        "        # if we got a better score, store the score and parameters\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_parameters = {'C': C, 'gamma': gamma}\n",
        "# rebuild a model on the combined training and validation set\n",
        "svm = SVC(**best_parameters)\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ICKM1B4S_qx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of SVC on train set: {:.2f}' .format(svm.score(X_train, y_train)))\n",
        "print('Accuracy of SVC on test set: {:.2f}' .format(svm.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "iDVFxa7jAdGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_scores_logreg = logreg.decision_function(X_test)\n",
        "precision_logreg, recall_logreg, thresholds_logreg = precision_recall_curve(y_test, y_scores_logreg)\n",
        "\n",
        "closest_zero_logreg = np.argmin(np.abs(thresholds_logreg))\n",
        "closest_zero_p_logreg = precision_logreg[closest_zero_logreg]\n",
        "closest_zero_r_logreg = recall_logreg[closest_zero_logreg]\n",
        "\n",
        "y_scores = svm.decision_function(X_test)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "closest_zero = np.argmin(np.abs(thresholds))\n",
        "closest_zero_p = precision[closest_zero]\n",
        "closest_zero_r = recall[closest_zero]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.xlim([0.0, 1.01])\n",
        "plt.ylim([0.0, 1.01])\n",
        "plt.plot(precision_logreg, recall_logreg, color='green', label='LogisticRegression Precision-Recall Curve')\n",
        "plt.plot(precision, recall, label='SVC Precision-Recall Curve')\n",
        "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle ='none', c='r', mew=3)\n",
        "plt.xlabel('Precision', fontsize=16)\n",
        "plt.ylabel('Recall', fontsize=16)\n",
        "plt.title('Precision-Recall_Curve_Comparison', fontsize=16)\n",
        "plt.legend(loc='lower left', fontsize=13)\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pMNLQpecBAxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr_lr_logreg, tpr_lr_logreg, _ = roc_curve(y_test, y_scores_logreg)\n",
        "roc_auc_lr_logreg = auc(fpr_lr_logreg, tpr_lr_logreg)\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores)\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.xlim([-0.01, 1.00])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.plot(fpr_lr_logreg, tpr_lr_logreg, lw=3, color='green', label='LogisticRegression ROC curve (area = {:0.2f})'.format(roc_auc_lr_logreg))\n",
        "plt.plot(fpr_lr, tpr_lr, lw=3, label='SVC ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate', fontsize=16)\n",
        "plt.title('ROC_Curve_Comparison', fontsize=16)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=3, linestyle='--')\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u6gTMTx8BVSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DTClf = DecisionTreeClassifier(random_state = 0)  #DTClf = Decision Tree Classifier\n",
        "DTClf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ScTLR24sBk7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Prediction = DTClf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "KV1qgcClB23c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'real or true values(y_test)': y_test, 'Model_Prediction': Model_Prediction}\n",
        "dfC = pd.DataFrame(data=d)\n",
        "dfC.head(10)"
      ],
      "metadata": {
        "id": "jK-FJoF5B_MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of Decision Tree classifier on train set: {:.2f}' .format(DTClf.score(X_train, y_train)))\n",
        "print('Accuracy of Decision Tree classifier on test set: {:.2f}' .format(DTClf.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "2Fll1RoXCLqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNClf = KNeighborsClassifier(n_neighbors = 1)  # KNClf= KNeighborsClassifier\n",
        "KNClf.fit(X_train_scaled, y_train) \n"
      ],
      "metadata": {
        "id": "AnLQ86qlCOXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Prediction_knn = KNClf.predict(X_test_scaled)\n",
        "Model_Prediction_knn"
      ],
      "metadata": {
        "id": "fGsRJzqLCsuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of KNeighborsClassifier on train set: {:.2f}' .format(KNClf.score(X_train_scaled, y_train)))\n",
        "print('Accuracy of KNeighborsClassifier on test set: {:.2f}' .format(KNClf.score(X_test_scaled, y_test)))"
      ],
      "metadata": {
        "id": "12DH1-wRCxlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "Ks = 15\n",
        "mean_acc = np.zeros((Ks-1))\n",
        "std_acc = np.zeros((Ks-1))\n",
        "\n",
        "for n in range(1,Ks):\n",
        "    \n",
        "    #Train Model and Predict\n",
        "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train_scaled, y_train)\n",
        "    yhat = neigh.predict(X_test_scaled)\n",
        "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
        "    \n",
        "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
        "    \n",
        "mean_acc"
      ],
      "metadata": {
        "id": "o8NDfZUvDN_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "plt.plot(range(1,Ks), mean_acc, 'g')\n",
        "plt.fill_between(range(1,Ks), mean_acc - 1 * std_acc, mean_acc + 1 * std_acc, alpha=0.10)\n",
        "plt.fill_between(range(1,Ks), mean_acc - 3 * std_acc, mean_acc + 3 * std_acc, alpha=0.10, color='blue')\n",
        "plt.legend(('Accuracy', '+/- 1xstd', '+/- 3xstd'))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Neighbors (K)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yZauoAsSDUFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best accuracy is {:.2f}\" .format(mean_acc.max()), \"with k =\", mean_acc.argmax()+ 1)\n"
      ],
      "metadata": {
        "id": "jajYKbZKD0vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm=cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    print(cm)\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    fmt='.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i , j] , fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Outcome')\n",
        "    plt.xlabel('Predicted Outcome')"
      ],
      "metadata": {
        "id": "2NAidhu2D6kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(y_test, Model_Prediction_knn, labels=[1,0])\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.grid(False)\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Outcome = (diabetes or 1)', 'Outcome = (no diabetes or 0)'], normalize = False)"
      ],
      "metadata": {
        "id": "7IeF71z2D8nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, Model_Prediction_knn))\n"
      ],
      "metadata": {
        "id": "UihpcfZ2EMBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}